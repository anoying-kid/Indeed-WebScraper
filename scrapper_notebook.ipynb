{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24986788",
   "metadata": {},
   "source": [
    "# This is a program for scrapping the jobs from the site indeed.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf060b7",
   "metadata": {},
   "source": [
    "## Library used\n",
    "    * bs4 or Beautifulsoup popular for scraping\n",
    "        * lxml is the most feature-rich and easy-to-use library for processing XML and HTML in the Python.\n",
    "    * asyncio for asynchronous programming\n",
    "    * aiohttp library used for getting aynchronous request.\n",
    "    * tqdm is used for the getting bars in iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801f74a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582737d3",
   "metadata": {},
   "source": [
    "## IndeedScraper Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4e4784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndeedScraper():\n",
    "    \n",
    "    # For storing the request\n",
    "    li= []\n",
    "    \n",
    "    # For storing the data\n",
    "    di= {}\n",
    "    \n",
    "    # job variable is used for naming dictionary( di ) key\n",
    "    job=1\n",
    "    \n",
    "    # Constructor getting the required data\n",
    "    def __init__(self, what, where, page_till):\n",
    "        self.what= what\n",
    "        self.where= where\n",
    "        self.page_till= page_till\n",
    "    \n",
    "    \n",
    "    # This will request the website for getting the page content\n",
    "    def get_task(self, s):\n",
    "        task= []\n",
    "        for page in range(self.page_till):\n",
    "            page= page*10\n",
    "            \n",
    "            # Page url\n",
    "            url= 'https://in.indeed.com/jobs'\n",
    "            \n",
    "            # Url parameters\n",
    "            query= {\n",
    "                'q': self.what,\n",
    "                'l': self.where,\n",
    "                'start': page\n",
    "            }\n",
    "            \n",
    "            # HTTP headers are widely used during web scraping because they allow access to otherwise blocked information.\n",
    "            headers= {\"User-Agent\" : \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.1 Safari/605.1.15\"}\n",
    "            \n",
    "            # Appending all the request in task list\n",
    "            task.append(s.get(url, params=query, headers=headers, ssl=False))\n",
    "        return task\n",
    "\n",
    "    \n",
    "    # req() function will ascynchronously request the data from website\n",
    "    async def req(self):\n",
    "        \n",
    "        # Creating the session\n",
    "        async with aiohttp.ClientSession() as s:\n",
    "            tasks= self.get_task(s)\n",
    "            responses= await asyncio.gather(*tasks)\n",
    "            \n",
    "            # tqdm() function is used for bars\n",
    "            for response in tqdm(responses, desc=\"Extracting Data!\"):\n",
    "                \n",
    "                # appending() all the request in li list\n",
    "                self.li.append(await response.text())\n",
    "                \n",
    "    # Try and except is used since some of the detail like companyName, companyReq, dateposted aren't there so\n",
    "    ## instead of getting the error we print jobs without them\n",
    "    \n",
    "    # title() function will scrap the title of the jobs\n",
    "    async def title(self, text, page, job):\n",
    "        soup= BeautifulSoup(text, 'lxml')\n",
    "        Title= soup.find_all('h2', attrs={\"class\": \"jobTitle jobTitle-color-purple\"})\n",
    "        for title in Title:\n",
    "            self.di[f'job{page}{job}']={}\n",
    "            self.di[f'job{page}{job}']['title']=title.find_next('span')['title']\n",
    "            job+=1\n",
    "    \n",
    "    # companyName() function will scrap the company name of the jobs\n",
    "    async def companyName(self, text, page, job):\n",
    "        soup=BeautifulSoup(text, 'lxml')\n",
    "        Title= soup.find_all('div', attrs={'class': 'heading6 company_location tapItem-gutter'})\n",
    "        for title in Title:\n",
    "            try:\n",
    "                self.di[f'job{page}{job}']['companyName']= title.pre.span.text\n",
    "                self.di[f'job{page}{job}']['companyLocation']= title.pre.div.text\n",
    "                job+=1\n",
    "            except KeyError:\n",
    "                pass\n",
    "    # companyReq() function will scrap the company requirements of the jobs\n",
    "    async def companyReq(self, text, page, job):\n",
    "        soup=BeautifulSoup(text, 'lxml')\n",
    "        Title= soup.find_all('div', attrs={'class': 'job-snippet'})\n",
    "        for title in Title:\n",
    "            try:\n",
    "                self.di[f'job{page}{job}']['companyReq']= f\"1) {title.ul.li.text}.\\n2) {title.ul.li.find_next('li').text}\"\n",
    "                job+=1\n",
    "            except KeyError:\n",
    "                pass\n",
    "            except AttributeError:\n",
    "                pass\n",
    "            \n",
    "    # datePosted() function will scrap the date when posted\n",
    "    async def datePosted(self, text, page, job):\n",
    "        soup=BeautifulSoup(text, 'lxml')\n",
    "        Title= soup.find_all('span', attrs={'class': 'date'})\n",
    "        for title in Title:\n",
    "            try:\n",
    "                self.di[f'job{page}{job}']['datePosted']= title.text\n",
    "                job+=1\n",
    "            except KeyError:\n",
    "                pass\n",
    "    \n",
    "    # getting all the stuff in one place\n",
    "    async def main(self):\n",
    "        page=1\n",
    "        \n",
    "        # This is done to follow DRY- Don't Repeat Yourself, we have same lines again and again so getattr is used.\n",
    "        function= [\"title\", \"companyName\", \"companyReq\", \"datePosted\"]\n",
    "\n",
    "        tasks=[]\n",
    "        \n",
    "        for fun in tqdm(function, desc=\"Clearing Data...\"):\n",
    "            for text in self.li:\n",
    "                \n",
    "                # getattr() method returns the value of the named attribute of an object\n",
    "                tasks.append(asyncio.create_task(getattr(self, fun)(text, page, self.job) ))\n",
    "                page+=1\n",
    "            await asyncio.gather(*tasks)\n",
    "            page=1\n",
    "\n",
    "        ## We can print this terminal also\n",
    "        # for i in self.di:\n",
    "        #     print('\\n')\n",
    "        #     for j in self.di[i]:\n",
    "        #         print(f'{j} : {self.di[i][j]}')\n",
    "        #     print('-----------------------\\n')\n",
    "        \n",
    "        # also saving the data in txt file\n",
    "        with open('data.txt', 'w') as w:\n",
    "            ls = []\n",
    "            for i in self.di:\n",
    "                ls.append('\\n')\n",
    "                for j in self.di[i]:\n",
    "                    ls.append(f\"{j.capitalize()} : {self.di[i][j].capitalize()}\\n\")\n",
    "                ls.append('-----------------------\\n')\n",
    "            w.write(''.join(ls))\n",
    "\n",
    "        print(f\"Number of jobs available {len(self.di)}\")\n",
    "\n",
    "## Uncomment these lines if running in ide not using jupyter\n",
    "#     def run(self):\n",
    "#         asyncio.run(self.req())\n",
    "#         asyncio.run(self.main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e981f8f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your profession, skill: python\n",
      "Where you want your job: delhi\n",
      "Number of page to extract: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Data!: 100%|███████████████████████████| 1/1 [00:02<00:00,  2.53s/it]\n",
      "Clearing Data...: 100%|███████████████████████████| 4/4 [00:00<00:00, 33.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of jobs available 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "skill= input(\"Your profession, skill: \")\n",
    "place= input(\"Where you want your job: \")\n",
    "page_till=int(input(\"Number of page to extract: \"))\n",
    "indeed = IndeedScraper(skill, place, page_till)\n",
    "await indeed.req()\n",
    "await indeed.main()\n",
    "\n",
    "## Uncomment these lines if running in ide not using jupyter\n",
    "# indeed.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fe702a",
   "metadata": {},
   "source": [
    "## creating our own filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08023109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jobs won't be shown with your skill you won't know\n",
    "def unknown_skill(di, word):\n",
    "    di_unknown = {}\n",
    "    for i,j in di.items():\n",
    "        if word not in j['companyReq'] and word not in j['title']:\n",
    "            di_unknown[i] = j\n",
    "    return di_unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8359a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jobs will be shown with skill you know\n",
    "def known_skill(di, word):\n",
    "    di_known = {}\n",
    "    for i,j in di.items():\n",
    "        if word in j['companyReq'] or word in j['title']:\n",
    "            di_known[i] = j\n",
    "    return di_known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48682cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = known_skill(indeed.di, 'ReactJS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824b898b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title:ReactJS Developer\n",
      "\n",
      "companyReq:1) The product division of AmeriCloud designs and develops SaaS based B2B2C solutions for several industries such as telecom, restaurant/hospitality and non-profit….\n",
      "2) View all AmeriCloud Solutions jobs - Delhi jobs\n",
      "\n",
      "datePosted:Posted7 days ago\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing required data\n",
    "for i in data.values():\n",
    "    for j,k in i.items():\n",
    "        print(f'{j}:{k}\\n')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59be917d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job11': {'title': 'Cybersecurity System Engineer (APAC)',\n",
       "  'companyReq': '1) The primary responsibilities will be to assist Clients in planning, design & implementation of their Cyber Security Incident Response system..\\n2) We aim to build carefully-architected planet-scale products with very few(<5k) lines of code, directly on top of AWS technology.',\n",
       "  'datePosted': 'EmployerActive 1 day ago'},\n",
       " 'job12': {'title': 'Hiring fresher for Python Development',\n",
       "  'companyReq': '1) We aim to build carefully-architected planet-scale products with very few(<5k) lines of code, directly on top of AWS technology..\\n2) Ability to work 100% remotely.',\n",
       "  'datePosted': 'Posted3 days ago'},\n",
       " 'job13': {'title': 'JavaScript/Python Developer Fresher',\n",
       "  'companyReq': '1) Developing back-end components to improve responsiveness and overall performance..\\n2) Integrating user-facing elements into applications.',\n",
       "  'datePosted': 'EmployerActive 1 day ago'},\n",
       " 'job14': {'title': 'Python Developer',\n",
       "  'companyReq': '1) Good understanding of C++,Java, Python, Data Structure, Javascript, Angular, React..\\n2) Training on Any Technology (Java, C++, Python, Data Science, Full Stack).',\n",
       "  'datePosted': 'Posted4 days ago'},\n",
       " 'job15': {'title': 'Python Developer',\n",
       "  'companyReq': '1) We aim to build carefully-architected planet-scale products with very few(<5k) lines of code, directly on top of AWS technology..\\n2) Ability to work 100% remotely.',\n",
       "  'datePosted': 'Posted3 days ago'},\n",
       " 'job16': {'title': 'Backend Developer',\n",
       "  'companyReq': '1) Our client is looking for a Junior Python Developer to assist senior resources and write Python code which is efficient and modular server-side code..\\n2) View all FENG GROUP jobs - New Delhi jobs',\n",
       "  'datePosted': 'Posted1 day ago'},\n",
       " 'job17': {'title': 'PYTHON DEVELOPER- FULL TIME',\n",
       "  'companyReq': '1) Experience : 3 to 5 Years..\\n2) Working Env : Linux / Unix / Centos.',\n",
       "  'datePosted': 'Posted2 days ago'},\n",
       " 'job21': {'title': 'PYTHON DEVELOPER- FULL TIME',\n",
       "  'companyReq': '1) This position requires a person who can independently design, develop, and implement solutions as per the use case descriptions and design specifications..\\n2) View all Immersive Infotech Pvt. Ltd jobs - Delhi jobs',\n",
       "  'datePosted': 'EmployerActive 2 days ago'},\n",
       " 'job22': {'title': 'Field Application Engineer',\n",
       "  'companyReq': '1) Good understanding of customer needs relative to product(s), technology, direction, competition, design process and design cycle from Defense, Aerospace and….\\n2) View all AdvanceTech Controls Pvt ltd jobs - Delhi jobs',\n",
       "  'datePosted': 'EmployerActive 1 day ago'},\n",
       " 'job23': {'title': 'Coding Teacher',\n",
       "  'companyReq': '1) Full time permanent remote position..\\n2) Working on machine and deep learning projects.',\n",
       "  'datePosted': 'Posted2 days ago'},\n",
       " 'job24': {'title': 'Data Engineer',\n",
       "  'companyReq': '1) In our ed-tech vertical we are looking for part time coding teachers..\\n2) Conducting demos for new partners and students.',\n",
       "  'datePosted': 'EmployerActive 2 days ago'},\n",
       " 'job25': {'title': 'online coding Instructor',\n",
       "  'companyReq': '1) Strong preference will be given to female engineers with certifications in Google Cloud Platform or AWS.*..\\n2) We are on the bleeding edge of data engineering and…',\n",
       "  'datePosted': 'EmployerActive 1 day ago'},\n",
       " 'job26': {'title': 'Software Testing Engineer',\n",
       "  'companyReq': '1) Back-end development using Python/Django..\\n2) Front-end development using CSS, HTML and JS.',\n",
       "  'datePosted': 'PostedJust posted'},\n",
       " 'job27': {'title': 'Coding Trainer for Kids (Part Time)',\n",
       "  'companyReq': '1) The candidate should be comfortable to teach both block based coding and text based JavaScript & python..\\n2) Conduct teacher training sessions.',\n",
       "  'datePosted': 'EmployerActive 1 day ago'},\n",
       " 'job28': {'title': 'Mobile App Developer',\n",
       "  'companyReq': '1) Graduate / Post Graduate in Computer Science or Electronics Having Prior Experience In Java / Python / Selenium*..\\n2) Total work: 1 year (Preferred).',\n",
       "  'datePosted': 'Hiring ongoing'},\n",
       " 'job29': {'title': 'Quality Analyst - Manual',\n",
       "  'companyReq': '1) We have course contents ready to deliver and looking for candidates to Work From Home (Part Time) with Flexible hours..\\n2) Part-time hours: 20 per week.',\n",
       "  'datePosted': 'EmployerActive 2 days ago'},\n",
       " 'job210': {'title': 'Python Developer',\n",
       "  'companyReq': '1) At EvoLive, a Mobile app Developer can expect to design flexible and scalable solutions and work on some challenging apps in large-scale computing by utilizing….\\n2) View all EvoLive jobs - Delhi jobs',\n",
       "  'datePosted': 'EmployerActive 24 days ago'},\n",
       " 'job211': {'title': 'Software Engineer',\n",
       "  'companyReq': '1) A Sr. Software Engineer – QA is responsible for building scalable automated test frameworks and test suites to work across technologies..\\n2) View all ZipLoan jobs - Delhi jobs',\n",
       "  'datePosted': 'Posted30+ days ago'},\n",
       " 'job31': {'title': 'Quality Analyst',\n",
       "  'companyReq': '1) Analyse test logs; create test reports, coordinate with stakeholders..\\n2) *Experience in test planning, test design, test strategy, and test execution.*.',\n",
       "  'datePosted': 'EmployerActive 1 day ago'},\n",
       " 'job32': {'title': 'RPA Developer',\n",
       "  'companyReq': '1) 2-5 years of work experience in related domain..\\n2) Job Types: Full-time, Regular / Permanent.',\n",
       "  'datePosted': 'EmployerActive 3 days ago'},\n",
       " 'job33': {'title': 'Looking for a coding teacher',\n",
       "  'companyReq': '1) Teach JavaScript-based courses (virtual reality/artificial intelligence) to kids aged 10-18 ages offline..\\n2) Conduct the first discovery class and ongoing classes…',\n",
       "  'datePosted': 'EmployerActive 3 days ago'},\n",
       " 'job34': {'title': 'Quality Analyst ( Automation & Manual) - Interns',\n",
       "  'companyReq': '1) Salary Pkg: No bar for Desired Candidate (Hike on Present/Previous CTC)..\\n2) Implement projects/assignments related to network maintenance, upgrade, scaling, etc.',\n",
       "  'datePosted': 'EmployerActive 3 days ago'},\n",
       " 'job35': {'title': 'Python Developer',\n",
       "  'companyReq': '1) Bytelearn is an AI tutor which can teach students, help them solve questions, give them problems to practice, make them learn concepts, provide data to parents….\\n2) View all Bytelearn Edtech Pvt Ltd jobs - Delhi jobs',\n",
       "  'datePosted': 'EmployerActive 9 days ago'},\n",
       " 'job36': {'title': 'Senior Software Engineer 1',\n",
       "  'companyReq': '1) We are confident that we can dramatically improve the experience of running complex business operations - and then we can help our customers embrace those new….\\n2) View all Canonical - Jobs jobs - Delhi jobs',\n",
       "  'datePosted': 'Posted1 day ago'},\n",
       " 'job37': {'title': 'Scientist - Remote sensing',\n",
       "  'companyReq': '1) Lead the due diligence process in terms of the nature of the intake activities, understand the requirement and communicate effectively..\\n2) View all EY jobs - Gurgaon Road jobs',\n",
       "  'datePosted': 'PostedToday'},\n",
       " 'job38': {'title': 'IT HR Recruiter',\n",
       "  'companyReq': '1) The person is going to be a part of a closely knit small team of passionate individuals with a single-minded focus to create genuinely world class EdTech….\\n2) View all Speako24 jobs - Delhi jobs',\n",
       "  'datePosted': 'Posted30+ days ago'},\n",
       " 'job39': {'title': 'Machine Learning Engineer',\n",
       "  'companyReq': '1) You’ll be part of a cross-functional team that’s responsible for the full software development life cycle, from conception to deployment..\\n2) View all Sentieo jobs - New Delhi jobs',\n",
       "  'datePosted': 'Posted30+ days ago'},\n",
       " 'job41': {'title': 'Blockchain Developer',\n",
       "  'companyReq': '1) Researching, designing and building blockchain components which enable roll out of larger commercial solutions..\\n2) Ability to work well in a small team.',\n",
       "  'datePosted': 'EmployerActive 2 days ago'},\n",
       " 'job42': {'title': 'Research Associate – RS&GIS',\n",
       "  'companyReq': '1) IORA is looking to hire a self-motivated, and hardworking individual with a good background in the domain of Remote Sensing and GIS applications, with special….\\n2) View all Iora Ecological Solutions jobs - New Delhi jobs',\n",
       "  'datePosted': 'Posted9 days ago'},\n",
       " 'job43': {'title': 'Field Application Engineer',\n",
       "  'companyReq': '1) Their reputations and success depend on our passion for solving their most complex measurement problems..\\n2) We help them measure, analyze and test next generation…',\n",
       "  'datePosted': 'Posted24 days ago'},\n",
       " 'job44': {'title': 'python developer',\n",
       "  'companyReq': '1) Ensure that all activities and duties are carried out in full compliance with regulatory requirements, Enterprise Wide Risk Management Framework and internal….\\n2) View all Barclays jobs - Delhi jobs',\n",
       "  'datePosted': 'Posted2 days ago'},\n",
       " 'job45': {'title': 'Software Trainer',\n",
       "  'companyReq': '1) Python Technical Developer/ Lead (Python + MySQL + Web Scraping ) will be responsible for efficient web scraping/web crawling and parsing..\\n2) View all Shelby Shielding Futures jobs - New Delhi jobs',\n",
       "  'datePosted': 'Posted18 days ago'},\n",
       " 'job46': {'title': 'Full Stack Developer',\n",
       "  'companyReq': '1) Efficient delivery of course modules..\\n2) Ensure student satisfaction with course content and course delivery.',\n",
       "  'datePosted': 'EmployerActive 16 days ago'},\n",
       " 'job47': {'title': 'Backend Developer (Django)',\n",
       "  'companyReq': '1) The GIS Head is responsible for development, direction, and management of all geospatial and related technological activities within the India Program..\\n2) View all The Nature Conservancy jobs - New Delhi jobs',\n",
       "  'datePosted': 'Posted2 days ago'},\n",
       " 'job51': {'title': 'Consultant – Analytics (DER)',\n",
       "  'companyReq': '1) We’re a lean team of designers and developers passionate about problem-solving using engineering and design thinking concepts..\\n2) Location: * New Delhi or Remote.',\n",
       "  'datePosted': 'EmployerActive 2 days ago'},\n",
       " 'job52': {'title': 'Ziploan Hiring For QA Role',\n",
       "  'companyReq': '1) As part of your role, you will have an opportunity to apply your academic knowledge and prior industry experience, gain exposure to major projects, interact….\\n2) View all ICF jobs - New Delhi jobs',\n",
       "  'datePosted': 'Posted30+ days ago'},\n",
       " 'job53': {'title': 'Python Developer',\n",
       "  'companyReq': '1) A Sr. Software Engineer – QA is responsible for building scalable automated test frameworks and test suites to work across technologies..\\n2) View all ZipLoan jobs - Connaught Place, Delhi, Delhi jobs',\n",
       "  'datePosted': 'Posted30+ days ago'},\n",
       " 'job54': {'title': 'Lead Backend Engineer',\n",
       "  'companyReq': '1) Good knowledge of metadata management, data modeling, and related tools..\\n2) Implementing data strategies, building data flows, and developing physical data models.',\n",
       "  'datePosted': 'Posted30+ days ago'},\n",
       " 'job55': {'title': 'Python Developer - India',\n",
       "  'companyReq': '1) Status, disability, gender identity, or Veteran status..\\n2) Freedom to evaluate and introduce new tools, libraries, or coding standards.',\n",
       "  'datePosted': 'Posted30+ days ago'},\n",
       " 'job56': {'title': 'Software Engineer (Python)',\n",
       "  'companyReq': '1) This position will report to the Director of Technology Partnerships and will be a key player in building a new integration framework..\\n2) View all Alertus jobs - Delhi jobs',\n",
       "  'datePosted': 'Posted30 days ago'},\n",
       " 'job57': {'title': 'MDR Security Analyst',\n",
       "  'companyReq': '1) You will have the responsibility of designing the best object oriented model for a particular problem..\\n2) Algorithms, analysis and performance optimization.',\n",
       "  'datePosted': 'Posted30+ days ago'},\n",
       " 'job58': {'title': 'Quality Engineer',\n",
       "  'companyReq': '1) Experience with SQL, bash, python, and powershell..\\n2) Proactively monitor and review threats and suspicious events from customers participating in the service.',\n",
       "  'datePosted': 'Posted11 days ago'},\n",
       " 'job59': {'title': 'ReactJS Developer',\n",
       "  'companyReq': '1) The product division of AmeriCloud designs and develops SaaS based B2B2C solutions for several industries such as telecom, restaurant/hospitality and non-profit….\\n2) View all AmeriCloud Solutions jobs - Delhi jobs',\n",
       "  'datePosted': 'Posted7 days ago'},\n",
       " 'job510': {'title': 'AI Data Scientist',\n",
       "  'companyReq': '1) Ensure that all activities and duties are carried out in full compliance with regulatory requirements, Enterprise Wide Risk Management Framework and internal….\\n2) View all Barclays jobs - Delhi jobs',\n",
       "  'datePosted': 'Posted6 days ago'},\n",
       " 'job511': {'title': 'IT Technical Corporate Trainer',\n",
       "  'companyReq': '1) You will be primarily responsible for quality assurance activities for digital products which support our Core Accounting function..\\n2) View all Boston Consulting Group jobs - New Delhi jobs',\n",
       "  'datePosted': 'Posted30+ days ago'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeed.di"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b15157bbf0b90143226f00c63263d7c548c78ff8835dfd1777e63cce64135c20"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 ('project_venv': venv)",
   "language": "python",
   "name": "python3100jvsc74a57bd0b15157bbf0b90143226f00c63263d7c548c78ff8835dfd1777e63cce64135c20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
